
# ğŸ¤– Jarvis AI Assistant

A local, voice-based desktop AI assistant â€” works **offline** using [Ollama](https://ollama.com), [Whisper](https://github.com/openai/whisper), and a Jarvis-style desktop UI.

---

## ğŸš€ Getting Started

### 1. Clone the Repository

```bash
git clone https://github.com/javidh357/jarvis_ai.git
cd jarvis_ai
```

### 2. Create and Activate a Virtual Environment

```bash
python -m venv .jack
.\.jack\Scriptsctivate
```

### 3. Install Dependencies

```bash
pip install -r requirements.txt
```

### 4. Start Ollama and Load the LLaMA Model

```bash
ollama run llama3
```

ğŸ’¡ You can also run `llama3:medium` or `llama3:large` if installed.

### 5. Run the Assistant

```bash
python main.py
```

---

## ğŸ“ Project Structure

```bash
jarvis_ai/
â”œâ”€â”€ main.py              # Starts the assistant
â”œâ”€â”€ nova_ai.py           # Core logic (transcribe, reply, speak)
â”œâ”€â”€ ui.py                # UI: animations, buttons, waveform
â”œâ”€â”€ database.py          # Save & retrieve chat history
â”œâ”€â”€ requirements.txt     # Dependencies
â””â”€â”€ README.md            # You're reading this
```

---

## ğŸ§  How It Works

- ğŸ™ï¸ Listens via your microphone (`sounddevice`)
- ğŸ“ Transcribes audio locally with Whisper (`openai-whisper`)
- ğŸ’¬ Sends the prompt to LLaMA 3 (`Ollama`)
- ğŸ—£ï¸ Speaks the reply using `pyttsx3`
- ğŸ–¥ï¸ Displays response in a custom animated UI (`tkinter`)

---

## ğŸ› ï¸ Coming Soon

- ğŸŒ Web search integration
- ğŸ–±ï¸ Mouse & keyboard control
- ğŸ§  Memory for past chats
- ğŸ”Œ Plugin support

---

## ğŸ™Œ Credits

Built by **Kovvuru Javidh**

Powered by:

- [Ollama](https://ollama.com)
- [Whisper by OpenAI](https://github.com/openai/whisper)
- [Tkinter](https://docs.python.org/3/library/tkinter.html)
- `pyttsx3`, `sounddevice`

---

## ğŸ“¸ Demo

ğŸ¥ Coming soon: YouTube video demo of Jarvis AI in action.

---

## ğŸ“œ License

Licensed under the [MIT License](LICENSE). Feel free to fork, improve, and build your own AI Jarvis.

